{% extends "base.html" %}

{% block title %}
How it works
{% endblock %}

{% block content %}

<style>
    .description_titles {
        color: #050404;
        font-family: sans-serif;
        text-align:center;
    }   

    .text {
        color: #181818;
        font-family: sans-serif;
        text-align:center;
    }

    .bloc1 {
        background-color:#DCD5D5;
        clear:both;
    }   

    .bloc2 {
        background-color:##FAF8F8;
        clear:both;
        display: block;
        margin-left: auto;
        margin-right: auto;
        width: 55%;
    } 

    .layer4 {
	border: solid 1px black;
	border-radius: 10%;
	/*display: block;
	margin-right: auto;
	margin-left: auto;*/
	width: 300px;
	height: 200px;
   }  

   .layer5 {
	border: solid 1px black;
	border-radius: 10%;
	/*display: block;
	margin-right: auto;
	margin-left: auto;*/
	width: 650px;
	height: 400px;
   }  
</style>

<div class='text'>

<!-- <div class='bloc1'> -->
	<!-- </br> -->
	<h1>How it works</h1>
</br>

    <p> Our colorizer algorithm is based on the <a href="https://phillipi.github.io/pix2pix/"> pix2pix </a> model from UC Berkeley.</p>
    <p> We adapted the architecture of the neural network for our project, coded the algorithm in TensorFlow and in PyTorch, wrapped it into a Flask API before serving it as a microservice through Google Cloud.</p>
    <p>The model relies on a cGAN (conditional Generative Adversarial Network) to learn a mapping between the space of grayscale images to colored images.</p>

</br>
<!-- </div> -->

<div class='bloc1'>
    <br/>
    <h1>Framing the problem</h1>
    <p>The problem consists in learning a mapping between the space of grayscale images (NxNx1 tensors) to the space of RGB images (NxNx3 tensors). </p>
    <p>
        <img class="layer4" title="Le protocole HTTP, en gros"
                src="http://image.noelshack.com/fichiers/2018/43/1/1540242905-untitled-drawing-1.png"
                align="center" />
     </p>
    <br/>
    <br/>

    <p>
        To do so, we train a neural network to colorize a black and white image.
    </p>
    <p>
        To put it in simple words, it is trained to learn to "color inside the lines" and to give plausible colors (i.e. green is not a plausible color for a face, unless you live in a galaxy far far away...).
    </p>
    <p>
        In a way, it's a bit like teaching a child to draw!
    </p>
    <p>
	    <img class="layer4" title="Le protocole HTTP, en gros"
            src="http://image.noelshack.com/fichiers/2018/42/5/1539943464-44464933-610070852728922-544077605129682944-n.jpg?fbclid=IwAR0Kk9OJe5LGC9vc0ZcZmw5cT2hyj_vvASvJPICZyEj5o8Z0nuILWxvwjRU"
            align="center" />
    </p>
    <br/>
</div>




<div class='bloc2'>
	<br>
<h1> Conditional Generative Adversarial Networks</h1>
    TBC
<p>Generative Adversarial Networks (GAN) are a class of deep learning models.
    It consists in two networks that are in competition with each other in a game theory scenario.
    </p><p> The first network, the generator, generates an image while the second, the discriminator, needs to detect
    whether the input image is real or generated. </p>
    <p>
    In our case, we are working with a conditional GAN that is the generator is given an input black and white image 
    from which to generate the colored image.  
</p>

<div id="attachment_965" class="wp-caption aligncenter">

			<!-- <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/4/1539872741-screen-shot-2018-10-18-at-15-35-16.png"
            width="800" height="400" align="center" /> -->

            <img class="layer5" title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539941385-1539872741-screen-shot-2018-10-18-at-15-35-16.png?fbclid=IwAR3axydhqHoaiLAeHoQCyZCTdIMA8WdqRfmOhXNoKPtos8wrKnpR0qw_qVs"
            width="800" height="400" align="center" /> 
		</a>


    </div>
    
<br>

<p> The Generator's job is to learn how to produce real looking colorized versions so that the 
    Discriminator can't distinguish between the generated image and the real one.</p>
    <p>
    The Discriminator needs to keep up with the Generator in order not to be fooled by its improvements.</p>
    <p>
    Eventually, the Generator learns well the underlying distribution of color images data and 
    is really good at generating colorised versions of black and white images.
</p>
</br>

</div>

<h1>Our Data</h1>


<img title="Le protocole HTTP, en gros" 
            src="https://www-tc.pbs.org/wgbh/nova/media/images/lfw-sample.width-800.jpg?fbclid=IwAR3m4v80e95_Xcbtj6PyWFvxyoG77hvSms2qqfrjmpgpFmxqIOt0QTmtyC8"
            align="center" width="1100" height="600"/>

<br>
<br>
<p>
	The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured.</p>
	<p> 1680 of the people pictured have two or more distinct photos in the data set. The only constraint on these faces is that they were detected by the Viola-Jones face detector.

</p>
</br>
<div class='bloc1'>
</br>
<h1>Our Model</h1>
</br>
<p>
	<img class="layer4" title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539943464-44464933-610070852728922-544077605129682944-n.jpg?fbclid=IwAR0Kk9OJe5LGC9vc0ZcZmw5cT2hyj_vvASvJPICZyEj5o8Z0nuILWxvwjRU"
            align="center" />
</p>
</br>
<p> Our model was trained on a library of more than 10 000 human portraits. The loss used is Binary Cross Entropy 
    for both the Generator and Discriminator to which we add a L1 loss for the Generator to obtain sharper images. </p>
    <p>
    The models were trained using an Adam optimizer  of learning rate 1e-4 and 1e-3 respectively. 
    The final layers of our neurals network are shown below.
</p>


</br>
</div>
</br>

<div id="attachment_965" class="wp-caption aligncenter">

            <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539943026-screen-shot-2018-10-19-at-11-56-30.png?fbclid=IwAR3s0aARp-Q-t7Pjd4wpd2tNRfyPEecJ4LUDPIt2OpJP5oo2UY7OdN3cHyo"
            width="900" height="550" align="center" />

            <!-- <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/4/1539879683-screen-shot-2018-10-18-at-18-20-59.png"
            width="900" height="550" align="center" /> -->

</div>
</br>
<div id="attachment_965" class="wp-caption aligncenter">

            <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539943018-screen-shot-2018-10-19-at-11-56-05.png?fbclid=IwAR1a9W3cMGq6LzsyyavASCq-axQT2u4Rw_d-r4tVV5VES1WNYFe730rsOPM"
            width="700" height="500" align="center" />

            <!-- <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/4/1539879497-screen-shot-2018-10-18-at-18-17-59.png"
            width="700" height="500" align="center" /> -->

</div>

<div class='bloc1'>
</br>
<h1>Training Loss</h1>
</br>
<p>
	<img title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539947421-loss.png?fbclid=IwAR2N04XAR716VQJPcUrkKX07pNNllIgbYoOyNEoANwSUUOVI2-fCWGO4poY"
            align="center" width="800" height="400"/>
</p>
<!-- </br> -->
<!-- <p> 
	<h3>Training Loss</h3>
</p> -->


</br>
</div>



<h1>Output of our Model</h1>
<!-- <p>
	Some stuff here 2
</p> -->
<br>

<div id="attachment_965" class="wp-caption aligncenter">

			<!-- <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/4/1539872741-screen-shot-2018-10-18-at-15-35-16.png"
            width="800" height="400" align="center" /> -->

            <img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539947871-untitled-drawing.jpg?fbclid=IwAR2tVWmpw4aldOO8fPMIGhp_-D8rSaK5eHotbZfz0xLP5Dpp7EKnu0-32Co"
            width="500" height="150" align="center" /> 
		</a>


    </div>
    
</br>
<br>
<p> On the left of the picture you can see an initial photo of Heidi Klum and Seal. We input the B&W version and obtain a coloured image afterwards.
</p>
</br>

<h2>
	Other examples
</h2>
<br>
	<img class=" wp-image-965 " title="Le protocole HTTP, en gros" 
            src="http://image.noelshack.com/fichiers/2018/42/5/1539943340-leaders.jpg?fbclid=IwAR2N04XAR716VQJPcUrkKX07pNNllIgbYoOyNEoANwSUUOVI2-fCWGO4poY"
            width="900" height="700" align="center" /> 

<p></p>
</div>

{% endblock %}